{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loguru\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from logger import FhpLogger\n",
    "from sklearn import datasets\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.fetch_california_housing()\n",
    "\n",
    "df = pd.DataFrame(data=data.data, columns=data.feature_names) \n",
    "df[data[\"target_names\"][0] ] = data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  MedHouseVal  \n",
       "0        -122.23        4.526  \n",
       "1        -122.22        3.585  \n",
       "2        -122.24        3.521  \n",
       "3        -122.25        3.413  \n",
       "4        -122.25        3.422  \n",
       "...          ...          ...  \n",
       "20635    -121.09        0.781  \n",
       "20636    -121.21        0.771  \n",
       "20637    -121.22        0.923  \n",
       "20638    -121.32        0.847  \n",
       "20639    -121.24        0.894  \n",
       "\n",
       "[20640 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation w/ Cross Validation\n",
    "def modelEval(train, test,feature=\"MedHouseVal\" ,model_id = 'dummy'):\n",
    "    \n",
    "    # Input: Feature & Target DataFrame\n",
    "\n",
    "    # Split feature/target variable\n",
    "    y = train[feature].copy()\n",
    "    X = train.copy()\n",
    "    del X[feature]     # remove target variable\n",
    "    \n",
    "    y_test = test[feature].copy()\n",
    "    X_test = test.copy()\n",
    "    del X_test[feature]\n",
    "    \n",
    "    # Pick Model \n",
    "    if(model_id == 'dummy'):    model = DummyRegressor()\n",
    "    if(model_id == 'rf'):    model = RandomForestRegressor(n_estimators=10,random_state=10)\n",
    "    \n",
    "    ''' Parameter Based Cross Validation (No Pipeline)'''\n",
    "#     gscv = GridSearchCV(model,param_grid,cv=5)\n",
    "#     gscv.fit(X,y)\n",
    "#     results = pd.DataFrame(gscv.cv_results_)\n",
    "#     scores = np.array(results.mean_test_score).reshape(7,7)\n",
    "    \n",
    "#     # plot the cross validation mean scores\n",
    "#     heatmap1(scores,xlabel='lamda',xticklabels=param_grid['lamd'],\n",
    "#                     ylabel='alpha',yticklabels=param_grid['alph'])\n",
    "    \n",
    "    ''' Standard Cross Validation '''\n",
    "    cv_score = np.sqrt(-cross_val_score(model,X,y,cv=5,scoring='neg_mean_squared_error'))\n",
    "    print(f\"Scores: {cv_score}, Mean: {cv_score.mean()}, std: {cv_score.std()}\" )\n",
    "\n",
    "    preds = model.fit(X, y)\n",
    "    preds = model.predict(X_test)\n",
    "    test_score = mean_squared_error(y_test, preds)\n",
    "    print(f\"Test score: {test_score}\")\n",
    "\n",
    "# function that imputes a dataframe \n",
    "def impute_knn(df):\n",
    "    \n",
    "    # imputation with KNN unsupervised method\n",
    "\n",
    "    # separate dataframe into numerical/categorical\n",
    "    ldf = df.select_dtypes(include=[np.number])           # select numerical columns in df\n",
    "    ldf_putaside = df.select_dtypes(exclude=[np.number])  # select categorical columns in df\n",
    "    # define columns w/ and w/o missing data\n",
    "    cols_nan = ldf.columns[ldf.isna().any()].tolist()         # columns w/ nan \n",
    "    cols_no_nan = ldf.columns.difference(cols_nan).values     # columns w/o nan \n",
    "\n",
    "    for col in cols_nan:                \n",
    "        imp_test = ldf[ldf[col].isna()]   # indicies which have missing data will become our test set\n",
    "        imp_train = ldf.dropna()          # all indicies which which have no missing data \n",
    "        model = KNeighborsRegressor(n_neighbors=5)  # KNR Unsupervised Approach\n",
    "        knr = model.fit(imp_train[cols_no_nan], imp_train[col])\n",
    "        ldf.loc[df[col].isna(), col] = knr.predict(imp_test[cols_no_nan])\n",
    "    \n",
    "    return pd.concat([ldf,ldf_putaside],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.9852729  0.94643386 0.98312595 0.98563789 0.98416468], Mean: 0.9769270557701788, std: 0.015272043602982274\n",
      "Test score: 0.9552074230851957\n",
      "Scores: [0.48206098 0.4619696  0.45967639 0.47500031 0.47536862], Mean: 0.4708151802139554, std: 0.008567776663917118\n",
      "Test score: 0.20424811111670002\n",
      "Scores: [0.9852729  0.94643386 0.98312595 0.98563789 0.98416468], Mean: 0.9769270557701788, std: 0.015272043602982274\n",
      "Test score: 0.9552074230851957\n",
      "Scores: [0.48230199 0.46138441 0.45927681 0.47437758 0.4752871 ], Mean: 0.47052557928773836, std: 0.008789648357027025\n",
      "Test score: 0.20429300755408383\n"
     ]
    }
   ],
   "source": [
    "data = datasets.fetch_california_housing()\n",
    "\n",
    "df = pd.DataFrame(data=data.data, columns=data.feature_names) \n",
    "df[data[\"target_names\"][0] ] = data[\"target\"]\n",
    "\n",
    "df2 = impute_knn(df)\n",
    "\n",
    "trdata,tedata = train_test_split(df2,test_size=0.3,random_state=42)\n",
    "trdata , tedata = trdata.copy(), tedata.copy()\n",
    "del df2, df\n",
    "# trdata_upd : training data w/ removed outliers\n",
    "maxval2 = trdata[data[\"target_names\"][0]].max() # get the maximum value\n",
    "trdata_upd = trdata[trdata[data[\"target_names\"][0] ] != maxval2].copy()\n",
    "tedata_upd = tedata[tedata[data[\"target_names\"][0] ] != maxval2].copy()\n",
    "# trdata_upd.hist(bins=60, figsize=(15,9),color=color1);\n",
    "# plt.show() # looks like its completely removed.\n",
    "\n",
    "# Make a feature that contains both longtitude & latitude\n",
    "trdata_upd['diag_coord'] = (trdata_upd['Longitude'] + trdata_upd['Latitude'])         # 'diagonal coordinate', works for this coord\n",
    "\n",
    "# update test data as well\n",
    "tedata_upd['diag_coord'] = (tedata_upd['Longitude'] + tedata_upd['Latitude'])\n",
    "\n",
    "features_cols = list(set(trdata_upd.columns)  ^ set([data[\"target_names\"][0]]))\n",
    "target_cols = data[\"target_names\"][0]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "trdata_upd[features_cols] = scaler.fit_transform(trdata_upd[features_cols])\n",
    "tedata_upd[features_cols] = scaler.transform(tedata_upd[features_cols])\n",
    "\n",
    "\n",
    "modelEval(trdata_upd, tedata_upd,model_id='dummy')\n",
    "modelEval(trdata_upd, tedata_upd,model_id='rf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('.venv-dev': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59ac8be3e9613d62f7b947950fc7248228b700f7c01a83223065edc5e02f9ba8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
