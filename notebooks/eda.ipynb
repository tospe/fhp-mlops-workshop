{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loguru\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from logger import FhpLogger\n",
    "from sklearn import datasets\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.fetch_california_housing()\n",
    "\n",
    "df = pd.DataFrame(data=data.data, columns=data.feature_names)\n",
    "df[data[\"target_names\"][0]] = data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation w/ Cross Validation\n",
    "def modelEval(train, test, feature=\"MedHouseVal\", model_id=\"dummy\"):\n",
    "\n",
    "    # Input: Feature & Target DataFrame\n",
    "\n",
    "    # Split feature/target variable\n",
    "    y = train[feature].copy()\n",
    "    X = train.copy()\n",
    "    del X[feature]  # remove target variable\n",
    "\n",
    "    y_test = test[feature].copy()\n",
    "    X_test = test.copy()\n",
    "    del X_test[feature]\n",
    "\n",
    "    # Pick Model\n",
    "    if model_id == \"dummy\":\n",
    "        model = DummyRegressor()\n",
    "    if model_id == \"rf\":\n",
    "        model = RandomForestRegressor(n_estimators=10, random_state=10)\n",
    "\n",
    "    \"\"\" Parameter Based Cross Validation (No Pipeline)\"\"\"\n",
    "    #     gscv = GridSearchCV(model,param_grid,cv=5)\n",
    "    #     gscv.fit(X,y)\n",
    "    #     results = pd.DataFrame(gscv.cv_results_)\n",
    "    #     scores = np.array(results.mean_test_score).reshape(7,7)\n",
    "\n",
    "    #     # plot the cross validation mean scores\n",
    "    #     heatmap1(scores,xlabel='lamda',xticklabels=param_grid['lamd'],\n",
    "    #                     ylabel='alpha',yticklabels=param_grid['alph'])\n",
    "\n",
    "    \"\"\" Standard Cross Validation \"\"\"\n",
    "    cv_score = np.sqrt(-cross_val_score(model, X, y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "    print(f\"Scores: {cv_score}, Mean: {cv_score.mean()}, std: {cv_score.std()}\")\n",
    "\n",
    "    preds = model.fit(X, y)\n",
    "    preds = model.predict(X_test)\n",
    "    test_score = mean_squared_error(y_test, preds)\n",
    "    print(f\"Test score: {test_score}\")\n",
    "\n",
    "\n",
    "# function that imputes a dataframe\n",
    "def impute_knn(df):\n",
    "\n",
    "    # imputation with KNN unsupervised method\n",
    "\n",
    "    # separate dataframe into numerical/categorical\n",
    "    ldf = df.select_dtypes(include=[np.number])  # select numerical columns in df\n",
    "    ldf_putaside = df.select_dtypes(exclude=[np.number])  # select categorical columns in df\n",
    "    # define columns w/ and w/o missing data\n",
    "    cols_nan = ldf.columns[ldf.isna().any()].tolist()  # columns w/ nan\n",
    "    cols_no_nan = ldf.columns.difference(cols_nan).values  # columns w/o nan\n",
    "\n",
    "    for col in cols_nan:\n",
    "        imp_test = ldf[ldf[col].isna()]  # indicies which have missing data will become our test set\n",
    "        imp_train = ldf.dropna()  # all indicies which which have no missing data\n",
    "        model = KNeighborsRegressor(n_neighbors=5)  # KNR Unsupervised Approach\n",
    "        knr = model.fit(imp_train[cols_no_nan], imp_train[col])\n",
    "        ldf.loc[df[col].isna(), col] = knr.predict(imp_test[cols_no_nan])\n",
    "\n",
    "    return pd.concat([ldf, ldf_putaside], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.fetch_california_housing()\n",
    "\n",
    "df = pd.DataFrame(data=data.data, columns=data.feature_names)\n",
    "df[data[\"target_names\"][0]] = data[\"target\"]\n",
    "\n",
    "df2 = impute_knn(df)\n",
    "\n",
    "trdata, tedata = train_test_split(df2, test_size=0.3, random_state=42)\n",
    "trdata, tedata = trdata.copy(), tedata.copy()\n",
    "del df2, df\n",
    "# trdata_upd : training data w/ removed outliers\n",
    "maxval2 = trdata[data[\"target_names\"][0]].max()  # get the maximum value\n",
    "trdata_upd = trdata[trdata[data[\"target_names\"][0]] != maxval2].copy()\n",
    "tedata_upd = tedata[tedata[data[\"target_names\"][0]] != maxval2].copy()\n",
    "# trdata_upd.hist(bins=60, figsize=(15,9),color=color1);\n",
    "# plt.show() # looks like its completely removed.\n",
    "\n",
    "# Make a feature that contains both longtitude & latitude\n",
    "trdata_upd[\"diag_coord\"] = (\n",
    "    trdata_upd[\"Longitude\"] + trdata_upd[\"Latitude\"]\n",
    ")  # 'diagonal coordinate', works for this coord\n",
    "\n",
    "# update test data as well\n",
    "tedata_upd[\"diag_coord\"] = tedata_upd[\"Longitude\"] + tedata_upd[\"Latitude\"]\n",
    "\n",
    "features_cols = list(set(trdata_upd.columns) ^ {data[\"target_names\"][0]})\n",
    "target_cols = data[\"target_names\"][0]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "trdata_upd[features_cols] = scaler.fit_transform(trdata_upd[features_cols])\n",
    "tedata_upd[features_cols] = scaler.transform(tedata_upd[features_cols])\n",
    "\n",
    "\n",
    "modelEval(trdata_upd, tedata_upd, model_id=\"dummy\")\n",
    "modelEval(trdata_upd, tedata_upd, model_id=\"rf\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "59ac8be3e9613d62f7b947950fc7248228b700f7c01a83223065edc5e02f9ba8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
